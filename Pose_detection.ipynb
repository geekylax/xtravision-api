{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"kYEub-OPbDt5"},"source":["This Notebook contains the code used for training and saving the trained model along with testing the model for batch of validation data points. \n","You are given an untrained model file with filename as \"untrained_model.pt\" and a csv file (val_norm.csv) containing the validation data points.\n","\n","Your task is to deploy an API for getting inference from the model file and using the API generate predictions for the validation data points. You may use Postman for hitting the API. You can create API using framework of your choice. \n","\n","You should be able to deploy the model inference API in some free cloud VM like from Heroku or AWS free tier. If you can not deploy on cloud then at least you will have to deploy in local environment but for this role you need to deploy models in cloud as API. Passing one row of val_norm.csv as parameter to API to generate predictions is sufficient and save the predictions in a text file. \n","\n","You will need to submit the text file with the predictions, input row of val_norm.csv as well as the code for the API. If you have deployed it in the cloud, submit the URL as well. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K0l71yS-Z7WW"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchsummary\n","from torch.utils.data import DataLoader, Dataset\n","import random\n","import numpy as np\n","import pandas as pd"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nLp1Jy4_aamh"},"outputs":[],"source":["np.random.seed(0)\n","random.seed(0)\n","torch.manual_seed(0)\n","torch.use_deterministic_algorithms(True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VtYXGpB8acHF"},"outputs":[],"source":["class PoseDataset(Dataset):\n","    \"\"\"Face Landmarks dataset.\"\"\"\n","\n","    def __init__(self, csv_file, transform=None):\n","        \"\"\"\n","        Args:\n","            csv_file (string): Path to the csv file with pose landmark locations.\n","\n","        \"\"\"\n","        self.pose_data = pd.read_csv(csv_file)\n","\n","\n","    def __len__(self):\n","        return len(self.pose_data)\n","\n","    def __getitem__(self, idx):\n","        \n","        item = torch.tensor(self.pose_data.iloc[idx, :-1], dtype=torch.float32)\n","        label = torch.tensor(self.pose_data.iloc[idx, -1], dtype=torch.int64)\n","        return item, label"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HagjnLB4aeoV"},"outputs":[],"source":["train_data = PoseDataset(\"train_norm.csv\")\n","test_data = PoseDataset(\"test_norm.csv\")\n","val_data = PoseDataset(\"val_norm.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GrmhQ9KVahOJ"},"outputs":[],"source":["train_loader = DataLoader(train_data, batch_size=64, shuffle=True, num_workers=0)\n","test_loader = DataLoader(test_data, batch_size=64, shuffle=True, num_workers=0)\n","val_loader = DataLoader(val_data, batch_size=64, shuffle=True, num_workers=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NM58ihLuai08"},"outputs":[],"source":["class DNN(nn.Module):\n","\n","    def __init__(self):\n","        super(DNN, self).__init__()\n","        # We will create a simple neural network with 2 fully connected layers for our use case\n","        self.fc1 = nn.Linear(99, 128)\n","        self.bn1 = nn.BatchNorm1d(128)\n","        self.fc2 = nn.Linear(128, 256)\n","        self.bn2 = nn.BatchNorm1d(256)\n","        self.fc3 = nn.Linear(256, 128)\n","        self.drop1 = nn.Dropout(p=0.4)\n","        self.fc4 = nn.Linear(128, 28) # 8 classes\n","\n","    def forward(self, x):\n","        x = F.relu(self.fc1(x))\n","        x = self.bn1(x)\n","        x = F.relu(self.fc2(x))\n","        x = self.bn2(x)\n","        x = F.relu(self.fc3(x))\n","        x = self.drop1(x)\n","        x = self.fc4(x)\n","        return x\n","\n","\n","dnn = DNN()\n","# torchsummary.summary(dnn, (99,), 16)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vPgIk7SnalBJ"},"outputs":[],"source":["import torch.optim as optim\n","\n","best_val_loss = 99999\n","best_model = None\n","best_val_accuracy = 0\n","# Create a function to train and validate the model and print out the accuracy and loss after every epoch.\n","def train_and_validate(model, criterion, optimizer, train_loader, validation_loader):\n","    \"\"\"Train and validate the model on training and validation datasets\n","\n","    Args:\n","        model (nn.Module): Neural network to be trained\n","        criterion (Callable): Loss function (Cross Entropy Loss)\n","        optimizer (Callable): Optimizer to use for training the model (SGD)\n","        train_loader (Generator): Train data loader\n","        validation_loader (Generator): Validation data loader\n","        BATCH_SIZE (int): Batch size to be used for training and validation\n","\n","    Returns:\n","        Tuple: Tuple of best model and best model validation accuracy\n","    \"\"\"\n","    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","    model.to(device)\n","\n","    print('Epoch:', epoch + 1)\n","    print('Training...')\n","    model.train()\n","    train_loss, train_accuracy = 0, 0\n","    for data, target in train_loader:\n","        data, target = data.to(device), target.to(device)\n","        optimizer.zero_grad()\n","        output = model(data)\n","         # print(output)\n","        loss = criterion(output, target)\n","        loss.backward()\n","        optimizer.step()\n","        train_loss += loss.item() * data.size(0)\n","        pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n","        # print(pred)\n","        train_accuracy += pred.eq(target.view_as(pred)).sum().item()\n","    train_loss /= len(train_data)\n","    train_accuracy /= len(train_data)\n","    print('Train loss: {:.4f}, Train accuracy: {:.4f}'.format(train_loss, train_accuracy))\n","    print('Validation...')\n","    model.eval()\n","    val_loss, val_accuracy = 0, 0\n","    with torch.no_grad():\n","        for data, target in validation_loader:\n","            data, target = data.to(device), target.to(device)\n","            output = model(data)\n","\n","            loss = criterion(output, target)\n","            val_loss += loss.item() * data.size(0)\n","            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n","            val_accuracy += pred.eq(target.view_as(pred)).sum().item()\n","        val_loss /= len(val_data)\n","        val_accuracy /= len(val_data)\n","        global best_val_loss\n","        global best_val_accuracy\n","        global best_model\n","        if val_accuracy > best_val_accuracy:\n","            print('Saving model...')\n","            torch.save(model, 'model.pt')\n","            best_val_loss = val_loss\n","            best_val_accuracy = val_accuracy\n","            print('Validation loss: {:.4f}, Validation accuracy: {:.4f}'.format(val_loss, val_accuracy))\n","            best_model = model\n","        print('Val loss: {:.4f}, Val accuracy: {:.4f}'.format(val_loss, val_accuracy))\n","        return best_model, best_val_accuracy\n","\n","            \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OuUQSCOIaqHl"},"outputs":[],"source":["model = DNN()\n","torch.save(model, \"untrained_model.pt\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BwqUSC4das3g"},"outputs":[],"source":["optimizer = optim.SGD(model.parameters(), lr=0.0001, momentum=0.9)\n","criterion = nn.CrossEntropyLoss()\n","\n","epochs = 10"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VhBJt1bpaydL"},"outputs":[],"source":["for epoch in range(epochs):\n","    best_model_weights, best_val_acc = train_and_validate(model, criterion, optimizer, train_loader, val_loader)\n","\n","print(f\"Best validation accuracy: {best_val_acc}\")"]},{"cell_type":"markdown","metadata":{"id":"xnVxXYvrbf8i"},"source":["# Model Testing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0qC0FhSkazEa"},"outputs":[],"source":["# Create a function to test the model on the test data and maintain a list of all the predictions.\n","def test_model(model, test_loader):\n","    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","    model.eval()\n","    test_loss, test_accuracy = 0, 0\n","    all_preds = []\n","    with torch.no_grad():\n","        for data, target in test_loader:\n","            data, target = data.to(device), target.to(device)\n","            output = model(data)\n","\n","            loss = criterion(output, target)\n","            test_loss += loss.item() * data.size(0)\n","            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n","            all_preds.append(pred)\n","            test_accuracy += pred.eq(target.view_as(pred)).sum().item()\n","        # test_loss /= len(test_data)\n","        # test_accuracy /= len(test_data)\n","\n","        print('Test loss: {:.4f}, Test accuracy: {:.4f}'.format(test_loss, test_accuracy))\n","    return all_preds\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KlxY-uZqa2_H"},"outputs":[],"source":["all_preds = test_model(model, val_loader)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4w0EYJJVa5nh"},"outputs":[],"source":["with open(\"val_preds.txt\", \"w\") as f:\n","    f.write(str(all_preds))"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyO3Cv+1DNmIP49eiDYBNaA1","collapsed_sections":[],"name":"Yoga_Pose_detection.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
